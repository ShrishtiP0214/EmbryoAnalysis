{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded trained model weights.\n",
      "Fused image saved as 'fused_output.jpg'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "\n",
    "# Allow loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Set a fixed seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Utility function to find common embryo IDs\n",
    "def get_common_embryo_ids(base_paths):\n",
    "    sets_of_ids = []\n",
    "    for path in base_paths:\n",
    "        subfolders = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "        sets_of_ids.append(set(subfolders))\n",
    "    common_ids = set.intersection(*sets_of_ids)\n",
    "    return sorted(list(common_ids))\n",
    "\n",
    "# U-Net building blocks\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=6, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1 = DoubleConv(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4 = DoubleConv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.conv5 = DoubleConv(512, 1024)\n",
    "        self.up6 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.conv6 = DoubleConv(1024, 512)\n",
    "        self.up7 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.conv7 = DoubleConv(512, 256)\n",
    "        self.up8 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.conv8 = DoubleConv(256, 128)\n",
    "        self.up9 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.conv9 = DoubleConv(128, 64)\n",
    "        self.conv10 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.pool1(c1)\n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.pool2(c2)\n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.pool3(c3)\n",
    "        c4 = self.conv4(p3)\n",
    "        p4 = self.pool4(c4)\n",
    "        c5 = self.conv5(p4)\n",
    "        up_6 = self.up6(c5)\n",
    "        merge6 = torch.cat([up_6, c4], dim=1)\n",
    "        c6 = self.conv6(merge6)\n",
    "        up_7 = self.up7(c6)\n",
    "        merge7 = torch.cat([up_7, c3], dim=1)\n",
    "        c7 = self.conv7(merge7)\n",
    "        up_8 = self.up8(c7)\n",
    "        merge8 = torch.cat([up_8, c2], dim=1)\n",
    "        c8 = self.conv8(merge8)\n",
    "        up_9 = self.up9(c8)\n",
    "        merge9 = torch.cat([up_9, c1], dim=1)\n",
    "        c9 = self.conv9(merge9)\n",
    "        output = self.conv10(c9)\n",
    "        return torch.sigmoid(output)\n",
    "\n",
    "# Custom Dataset for t3 phase and random samples\n",
    "class EmbryoT3Dataset(Dataset):\n",
    "    def __init__(self, base_paths, phase_csv_dir, embryo_ids, transform=None, num_t3_embryos=150, num_other_embryos=50):\n",
    "        if len(base_paths) != 6:\n",
    "            raise ValueError(\"Exactly 6 focal-plane directories are required.\")\n",
    "        \n",
    "        self.base_paths = base_paths\n",
    "        self.phase_csv_dir = phase_csv_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        t3_embryos = []\n",
    "        for eid in embryo_ids:\n",
    "            csv_path = os.path.join(phase_csv_dir, f\"{eid}_phases.csv\")\n",
    "            if os.path.exists(csv_path):\n",
    "                df = pd.read_csv(csv_path, header=None, names=['phase', 'start_frame', 'end_frame'])\n",
    "                t3_row = df[df['phase'] == 't3']\n",
    "                if not t3_row.empty and t3_row['start_frame'].iloc[0] <= t3_row['end_frame'].iloc[0]:\n",
    "                    t3_embryos.append((eid, t3_row['start_frame'].iloc[0], t3_row['end_frame'].iloc[0]))\n",
    "        \n",
    "        self.t3_embryos = random.sample(t3_embryos, min(num_t3_embryos, len(t3_embryos)))\n",
    "        t3_ids = set(eid for eid, _, _ in self.t3_embryos)\n",
    "        other_ids = [eid for eid in embryo_ids if eid not in t3_ids]\n",
    "        self.other_embryos = random.sample(other_ids, min(num_other_embryos, len(other_ids)))\n",
    "        \n",
    "        self.embryo_to_frames = {}\n",
    "        self.embryo_to_frame_files = {}\n",
    "        for eid in [eid for eid, _, _ in self.t3_embryos] + self.other_embryos:\n",
    "            subfolder = os.path.join(base_paths[0], eid)\n",
    "            image_files = sorted([f for f in os.listdir(subfolder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            frames = []\n",
    "            frame_files = {}\n",
    "            for f in image_files:\n",
    "                frame = extract_frame_number(f)\n",
    "                if frame is not None:\n",
    "                    frames.append(frame)\n",
    "                    frame_files[frame] = f\n",
    "            self.embryo_to_frames[eid] = sorted(frames)\n",
    "            self.embryo_to_frame_files[eid] = frame_files\n",
    "        \n",
    "        self.samples = []\n",
    "        for eid, start, end in self.t3_embryos:\n",
    "            available_t3_frames = [f for f in self.embryo_to_frames[eid] if start <= f <= end]\n",
    "            selected_frames = random.sample(available_t3_frames, min(2, len(available_t3_frames)))\n",
    "            for frame in selected_frames:\n",
    "                self.samples.append((eid, frame))\n",
    "        for eid in self.other_embryos:\n",
    "            available_frames = self.embryo_to_frames[eid]\n",
    "            selected_frames = random.sample(available_frames, min(2, len(available_frames)))\n",
    "            for frame in selected_frames:\n",
    "                self.samples.append((eid, frame))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embryo_id, frame = self.samples[idx]\n",
    "        filename = self.embryo_to_frame_files[embryo_id][frame]\n",
    "        \n",
    "        focal_images = []\n",
    "        for path in self.base_paths:\n",
    "            img_path = os.path.join(path, embryo_id, filename)\n",
    "            image = Image.open(img_path).convert('L')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            focal_images.append(image)\n",
    "        \n",
    "        input_tensor = torch.cat(focal_images, dim=0)\n",
    "        target = focal_images[2]  # Using third focal plane as dummy target\n",
    "        return input_tensor, target\n",
    "\n",
    "def extract_frame_number(filename):\n",
    "    match = re.search(r'RUN(\\d+)', filename)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "# Loss Functions\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_score = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
    "        return 1 - dice_score\n",
    "\n",
    "def combined_loss(output, target):\n",
    "    dice_loss_fn = DiceLoss()\n",
    "    l1_loss_fn = nn.L1Loss()\n",
    "    dice = dice_loss_fn(output, target)\n",
    "    l1 = l1_loss_fn(output, target)\n",
    "    return dice + l1\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, num_epochs=50, device='cpu'):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = combined_loss(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * inputs.size(0)\n",
    "        train_loss = running_train_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = combined_loss(outputs, targets)\n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "        val_loss = running_val_loss / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'embryo_unet_t3.pth')\n",
    "            print(f\"  [*] Model saved at epoch {epoch+1}\")\n",
    "\n",
    "# Testing Function for 6 Custom Images\n",
    "def test_single_embryo(model, image_paths, transform, device='cpu'):\n",
    "    \"\"\"\n",
    "    Test the U-Net model with 6 custom images from the same embryo across focal planes.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained U-Net model.\n",
    "        image_paths (list): List of 6 image paths (one per focal plane).\n",
    "        transform (callable): Transformations to apply to images (same as training).\n",
    "        device (str): Device to run inference on ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "        PIL.Image: Fused output image.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and preprocess the 6 images\n",
    "    focal_tensors = []\n",
    "    for path in image_paths:\n",
    "        img = Image.open(path).convert('L')\n",
    "        img_tensor = transform(img)\n",
    "        focal_tensors.append(img_tensor)\n",
    "    \n",
    "    # Stack into a 6-channel input tensor and add batch dimension\n",
    "    input_tensor = torch.cat(focal_tensors, dim=0)  # Shape: (6, H, W)\n",
    "    input_tensor = input_tensor.unsqueeze(0).to(device)  # Shape: (1, 6, H, W)\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)  # Shape: (1, 1, H, W)\n",
    "    \n",
    "    # Convert output tensor to PIL image\n",
    "    output_image = output.squeeze(0).cpu()  # Shape: (1, H, W)\n",
    "    fused_pil = transforms.ToPILImage()(output_image)\n",
    "    return fused_pil\n",
    "\n",
    "# Main Training Function\n",
    "def main_train(seed=42):\n",
    "    set_seed(seed)\n",
    "\n",
    "    base_paths = [\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F15\",\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F-15\",\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F30\",\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F-30\",\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F45\",\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F-45\"\n",
    "    ]\n",
    "    phase_csv_dir = r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_annotations\"\n",
    "    \n",
    "    embryo_ids = get_common_embryo_ids(base_paths)\n",
    "    print(f\"Found {len(embryo_ids)} embryo IDs: {embryo_ids[:5]} ...\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    dataset = EmbryoT3Dataset(\n",
    "        base_paths=base_paths,\n",
    "        phase_csv_dir=phase_csv_dir,\n",
    "        embryo_ids=embryo_ids,\n",
    "        transform=transform,\n",
    "        num_t3_embryos=150,\n",
    "        num_other_embryos=50\n",
    "    )\n",
    "    \n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = UNet(in_channels=6, out_channels=1).to(device)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    train_model(model, train_loader, val_loader, num_epochs=50, device=device)\n",
    "    print(\"Training complete. Best model saved as 'embryo_unet_t3.pth'.\")\n",
    "\n",
    "# Main Testing Function\n",
    "def main_test():\n",
    "    # Define the same transform used during training\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # Define paths to 6 custom images (update these paths to your images)\n",
    "    test_image_paths = [\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F15\\AB91-1\\D2013.01.29_S0719_I132_WELL1_RUN150.jpeg\",\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F30\\AB91-1\\D2013.01.29_S0719_I132_WELL1_RUN150.jpeg\",\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F45\\AB91-1\\D2013.01.29_S0719_I132_WELL1_RUN150.jpeg\",\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F-30\\AB91-1\\D2013.01.29_S0719_I132_WELL1_RUN150.jpeg\",\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F-15\\AB91-1\\D2013.01.29_S0719_I132_WELL1_RUN150.jpeg\",\n",
    "        r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F-45\\AB91-1\\D2013.01.29_S0719_I132_WELL1_RUN150.jpeg\"\n",
    "    ]\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load the trained model\n",
    "    model = UNet(in_channels=6, out_channels=1).to(device)\n",
    "    model_path = 'embryo_unet_t3.pth'\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(\"Loaded trained model weights.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Trained model 'embryo_unet_t3.pth' not found. Please train the model first.\")\n",
    "    \n",
    "    # Test with the 6 custom images\n",
    "    fused_image = test_single_embryo(model, test_image_paths, transform, device)\n",
    "    \n",
    "    # Save the fused image\n",
    "    fused_image.save(\"fused_output.jpg\")\n",
    "    print(\"Fused image saved as 'fused_output.jpg'.\")\n",
    "    \n",
    "    # Optionally display the image (requires a GUI environment)\n",
    "    # fused_image.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Uncomment to train the model\n",
    "    # main_train(seed=42)\n",
    "    \n",
    "    # Run the test with 6 custom images\n",
    "    main_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embryo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
