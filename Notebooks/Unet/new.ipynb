{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de284d63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# 4) Load model\u001b[39;00m\n\u001b[0;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m UNet(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m---> 41\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[43mMODEL_PATH\u001b[49m, map_location\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[0;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state)\n\u001b[0;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MODEL_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from torchvision import transforms\n",
    "import import_ipynb           # makes Python aware of .ipynb modules\n",
    "import unetDiceLoss_with_L1_modified               # references deepunet.ipynb\n",
    "from unetDiceLoss_with_L1_modified import UNet\n",
    "\n",
    "# 1) Configuration\n",
    "BASE_PATHS = [\n",
    "    r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F15\",\n",
    "    r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F-15\",\n",
    "    r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F30\",\n",
    "    r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F-30\",\n",
    "    r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F45\",\n",
    "    r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset_F-45\",\n",
    "]\n",
    "GT_PATH     = r\"C:\\Projects\\Embryo\\Dataset\\embryo_dataset\"\n",
    "MODEL_PATH  = \"embryo_unet.pth\"\n",
    "EMBRYO_ID   = \"AB91-1\"   # change to your series\n",
    "DEVICE      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2) Preprocessing transforms\n",
    "#   - for model input: resize & to-tensor\n",
    "tf_model = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 3) Helper to extract frame number\n",
    "def frame_num(fn):\n",
    "    m = re.search(r'RUN(\\d+)', fn)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# 4) Load model\n",
    "model = UNet(in_channels=6, out_channels=1).to(DEVICE)\n",
    "state = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# 5) Gather all focal filenames for this embryo\n",
    "fns = sorted(os.listdir(os.path.join(BASE_PATHS[0], EMBRYO_ID)))\n",
    "# filter only those matching RUN\\d+\n",
    "fns = [fn for fn in fns if frame_num(fn) is not None]\n",
    "\n",
    "scores = []\n",
    "frames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for fn in fns:\n",
    "        num = frame_num(fn)\n",
    "        # load 6 focal planes\n",
    "        channels = []\n",
    "        for bp in BASE_PATHS:\n",
    "            img = Image.open(os.path.join(bp, EMBRYO_ID, fn)).convert('L')\n",
    "            channels.append(tf_model(img))\n",
    "        inp = torch.cat(channels, dim=0).unsqueeze(0).to(DEVICE)  # (1,6,H,W)\n",
    "\n",
    "        # forward\n",
    "        out = model(inp).squeeze(0).cpu()  # (1,H,W)\n",
    "        fused = out.numpy().squeeze()\n",
    "\n",
    "        # load GT F0\n",
    "        gt = np.array(Image.open(os.path.join(GT_PATH, EMBRYO_ID, fn)).resize((256,256)).convert('L'))\n",
    "\n",
    "        # compute SSIM\n",
    "        score = ssim(gt, fused,\n",
    "                     data_range=fused.max()-fused.min(),\n",
    "                     win_size=11,\n",
    "                     gaussian_weights=True)\n",
    "        frames.append(num)\n",
    "        scores.append(score)\n",
    "\n",
    "# 6) Sort by frame number\n",
    "pairs = sorted(zip(frames, scores))\n",
    "frames, scores = zip(*pairs)\n",
    "\n",
    "# 7) Plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(frames, scores, marker='o')\n",
    "plt.xlabel(\"Frame Number (Time)\")\n",
    "plt.ylabel(\"SSIM\")\n",
    "plt.title(f\"SSIM vs. Time for Embryo {EMBRYO_ID}\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"ssim_vs_time_{EMBRYO_ID}.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df7800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embryo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
