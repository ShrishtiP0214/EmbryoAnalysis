{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a4413",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 validation error for InitSchema\ninterpolation\n  Input should be 0, 1, 2, 3 or 4 [type=literal_error, input_value=0.5, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.10/v/literal_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Projects\\Embryo\\embryo_env\\Lib\\site-packages\\albumentations\\core\\validation.py:64\u001b[0m, in \u001b[0;36mValidatedTransformMeta._validate_parameters\u001b[1;34m(schema_cls, full_kwargs, param_names, strict)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mschema_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfull_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam_names\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     validated_kwargs \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32mc:\\Projects\\Embryo\\embryo_env\\Lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for InitSchema\ninterpolation\n  Input should be 0, 1, 2, 3 or 4 [type=literal_error, input_value=0.5, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.10/v/literal_error",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 129\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Transforms\u001b[39;00m\n\u001b[0;32m    128\u001b[0m train_tf \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mCompose([A\u001b[38;5;241m.\u001b[39mHorizontalFlip(\u001b[38;5;241m0.5\u001b[39m), A\u001b[38;5;241m.\u001b[39mRandomRotate90(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m--> 129\u001b[0m                       \u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mShiftScaleRotate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m, ToTensorV2()])\n\u001b[0;32m    130\u001b[0m val_tf   \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mCompose([ToTensorV2()])\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Datasets & loaders\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projects\\Embryo\\embryo_env\\Lib\\site-packages\\albumentations\\core\\validation.py:102\u001b[0m, in \u001b[0;36mValidatedTransformMeta.__new__.<locals>.custom_init\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcustom_init\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     full_kwargs, param_names, strict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_process_init_parameters(original_init, args, kwargs)\n\u001b[1;32m--> 102\u001b[0m     validated_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdct\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInitSchema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparam_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_default_values(signature(original_init)\u001b[38;5;241m.\u001b[39mparameters)\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# Store and check invalid args\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     invalid_args \u001b[38;5;241m=\u001b[39m [name_arg \u001b[38;5;28;01mfor\u001b[39;00m name_arg \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m name_arg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m param_names \u001b[38;5;129;01mand\u001b[39;00m name_arg \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Projects\\Embryo\\embryo_env\\Lib\\site-packages\\albumentations\\core\\validation.py:68\u001b[0m, in \u001b[0;36mValidatedTransformMeta._validate_parameters\u001b[1;34m(schema_cls, full_kwargs, param_names, strict)\u001b[0m\n\u001b[0;32m     66\u001b[0m     validated_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m strict:\n",
      "\u001b[1;31mValueError\u001b[0m: 1 validation error for InitSchema\ninterpolation\n  Input should be 0, 1, 2, 3 or 4 [type=literal_error, input_value=0.5, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.10/v/literal_error"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from segmentation_models_pytorch import Unet\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Regex to extract frame/run number from filename, e.g. '..._RUN12.jpeg'\n",
    "frame_re = re.compile(r\"RUN(\\d+)\", re.IGNORECASE)\n",
    "\n",
    "def extract_frame_number(filename):\n",
    "    m = frame_re.search(filename)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# Utility: get common embryo IDs\n",
    "def get_common_embryo_ids(annotations_path, image_dirs):\n",
    "    # CSV IDs\n",
    "    csv_ids = [fname.replace('_phases.csv', '')\n",
    "               for fname in os.listdir(annotations_path)\n",
    "               if fname.endswith('_phases.csv')]\n",
    "    csv_set = set(csv_ids)\n",
    "    # Dir IDs\n",
    "    dir_sets = []\n",
    "    for d in image_dirs:\n",
    "        if os.path.isdir(d):\n",
    "            subs = [dn for dn in os.listdir(d)\n",
    "                    if os.path.isdir(os.path.join(d, dn))]\n",
    "            dir_sets.append(set(subs))\n",
    "    common_dirs = set.intersection(*dir_sets) if dir_sets else set()\n",
    "    return sorted(csv_set & common_dirs)\n",
    "\n",
    "# Paths & config\n",
    "base = r'C:\\Projects\\Embryo\\Dataset'\n",
    "annotations_path = os.path.join(base, 'embryo_dataset_annotations')\n",
    "gt_path          = os.path.join(base, 'embryo_dataset')\n",
    "focal_dirs = {\n",
    "    'F15':  os.path.join(base, 'embryo_dataset_F15'),\n",
    "    'F-15': os.path.join(base, 'embryo_dataset_F-15'),\n",
    "    'F30':  os.path.join(base, 'embryo_dataset_F30'),\n",
    "    'F-30': os.path.join(base, 'embryo_dataset_F-30'),\n",
    "    'F45':  os.path.join(base, 'embryo_dataset_F45'),\n",
    "    'F-45': os.path.join(base, 'embryo_dataset_F-45')\n",
    "}\n",
    "focal_planes = list(focal_dirs.keys())\n",
    "H, W = 256, 256\n",
    "# Gather IDs\n",
    "dirs = [gt_path] + list(focal_dirs.values())\n",
    "ids = get_common_embryo_ids(annotations_path, dirs)\n",
    "if not ids:\n",
    "    raise ValueError(\"No common embryo IDs found.\")\n",
    "train_ids, val_ids = train_test_split(ids, test_size=0.2, random_state=42)\n",
    "\n",
    "class EmbryoT4Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads all T4-phase frames per embryo; builds 6-channel stack and GT mask.\n",
    "    \"\"\"\n",
    "    def __init__(self, embryo_ids, annotations_path, focal_dirs, gt_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []  # list of (eid, frame_number, filename)\n",
    "        self.focal_dirs = focal_dirs\n",
    "        self.gt_path = gt_path\n",
    "        # Build file list for each embryo\n",
    "        for eid in embryo_ids:\n",
    "            # read phase CSV\n",
    "            csv = os.path.join(annotations_path, f\"{eid}_phases.csv\")\n",
    "            if not os.path.exists(csv):\n",
    "                continue\n",
    "            df = pd.read_csv(csv, names=['phase','start','end'])\n",
    "            t4 = df[df['phase']=='t4']\n",
    "            if t4.empty:\n",
    "                continue\n",
    "            s, e = int(t4['start'].iloc[0]), int(t4['end'].iloc[0])\n",
    "            # list filenames in one focal dir to iterate runs\n",
    "            sample_dir = focal_dirs[focal_planes[0]]\n",
    "            files = [f for f in os.listdir(os.path.join(sample_dir, eid))\n",
    "                     if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "            for fname in files:\n",
    "                fr = extract_frame_number(fname)\n",
    "                if fr and s <= fr <= e:\n",
    "                    self.samples.append((eid, fr, fname))\n",
    "        if not self.samples:\n",
    "            raise ValueError(\"No T4 samples found.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eid, fr, fname = self.samples[idx]\n",
    "        # build stack: use the same fname across all focal dirs\n",
    "        stack = []\n",
    "        for fp in focal_planes:\n",
    "            p = os.path.join(self.focal_dirs[fp], eid, fname)\n",
    "            if not os.path.exists(p): raise FileNotFoundError(p)\n",
    "            im = imread(p, as_gray=True)\n",
    "            im = resize(im, (H, W), preserve_range=True)/255.0\n",
    "            stack.append(im)\n",
    "        inp = np.stack(stack, -1)\n",
    "        # GT mask: find corresponding GT filename by frame number\n",
    "        gt_files = os.listdir(os.path.join(self.gt_path, eid))\n",
    "        gt_fname = next((g for g in gt_files if extract_frame_number(g)==fr), None)\n",
    "        if gt_fname is None:\n",
    "            raise FileNotFoundError(f\"GT for frame {fr} not found for {eid}\")\n",
    "        g = imread(os.path.join(self.gt_path, eid, gt_fname), as_gray=True)\n",
    "        g = resize(g, (H, W), preserve_range=True)\n",
    "        mask = (g>threshold_otsu(g)).astype(np.float32)\n",
    "        # augment\n",
    "        if self.transform:\n",
    "            aug = self.transform(image=inp, mask=mask)\n",
    "            x = aug['image']\n",
    "            y = aug['mask'].unsqueeze(0)\n",
    "        else:\n",
    "            x = torch.tensor(inp).permute(2,0,1).float()\n",
    "            y = torch.tensor(mask).unsqueeze(0)\n",
    "        return x, y\n",
    "\n",
    "# Transforms\n",
    "train_tf = A.Compose([A.HorizontalFlip(0.5), A.RandomRotate90(0.5),\n",
    "                      A.ShiftScaleRotate(0.1,0.1,10,0.5), ToTensorV2()])\n",
    "val_tf   = A.Compose([ToTensorV2()])\n",
    "\n",
    "# Datasets & loaders\n",
    "train_ds = EmbryoT4Dataset(train_ids, annotations_path, focal_dirs, gt_path, transform=train_tf)\n",
    "val_ds   = EmbryoT4Dataset(val_ids,   annotations_path, focal_dirs, gt_path, transform=val_tf)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "# Model & training setup\n",
    "model = Unet('resnet34', in_channels=len(focal_planes), classes=1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "opt = Adam(model.parameters(), lr=1e-4)\n",
    "crit = BCEWithLogitsLoss()\n",
    "\n",
    "def dice(pred, tgt, smooth=1e-6):\n",
    "    p = pred.view(-1); t = tgt.view(-1)\n",
    "    i = (p*t).sum()\n",
    "    return (2*i+smooth)/(p.sum()+t.sum()+smooth)\n",
    "\n",
    "# Train loop\n",
    "best_loss = float('inf'); patience=10; wait=0\n",
    "for epoch in range(50):\n",
    "    model.train(); tloss=0\n",
    "    for x,y in tqdm(train_loader, desc=f\"Train {epoch+1}\"):\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        opt.zero_grad(); out = model(x)\n",
    "        loss = crit(out, y); loss.backward(); opt.step()\n",
    "        tloss += loss.item()\n",
    "    tloss /= len(train_loader)\n",
    "    model.eval(); vloss=0; vdice=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in val_loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            vloss += crit(out,y).item()\n",
    "            vdice += dice((torch.sigmoid(out)>0.5).float(), y).item()\n",
    "    vloss/=len(val_loader); vdice/=len(val_loader)\n",
    "    print(f\"Epoch {epoch+1}: Train {tloss:.4f} | Val {vloss:.4f} | Dice {vdice:.4f}\")\n",
    "    if vloss<best_loss:\n",
    "        best_loss=vloss; torch.save(model.state_dict(),'best_model.pth'); wait=0\n",
    "    else:\n",
    "        wait+=1\n",
    "        if wait>=patience:\n",
    "            print(\"Early stopping.\"); break\n",
    "\n",
    "# Load best\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "print(\"Done, saved best_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7cbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embryo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
