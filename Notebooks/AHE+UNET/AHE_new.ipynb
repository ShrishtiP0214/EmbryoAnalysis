{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c5db9fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'E:\\\\EmbryoAnalysis\\\\EmbryoAnalysis\\\\Dataset\\\\embryo_dataset_F15\\\\embryo_dataset_F15\\\\RLFS800-2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 138\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# === Run ===\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 138\u001b[0m     \u001b[43mtrain_and_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m     test_model()\n",
      "Cell \u001b[1;32mIn[4], line 91\u001b[0m, in \u001b[0;36mtrain_and_save_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     90\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     92\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     93\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    739\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 53\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_dir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dirs:\n\u001b[0;32m     52\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_names[idx])\n\u001b[1;32m---> 53\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m     img \u001b[38;5;241m=\u001b[39m apply_ahe(img)\n\u001b[0;32m     55\u001b[0m     input_tensors\u001b[38;5;241m.\u001b[39mappend(transforms\u001b[38;5;241m.\u001b[39mToTensor()(img))\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3465\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3462\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fp)\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3465\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3466\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'E:\\\\EmbryoAnalysis\\\\EmbryoAnalysis\\\\Dataset\\\\embryo_dataset_F15\\\\embryo_dataset_F15\\\\RLFS800-2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "# === Apply Adaptive Histogram Equalization ===\n",
    "def apply_ahe(image):\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "    enhanced = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
    "    return Image.fromarray(img_as_ubyte(enhanced))\n",
    "\n",
    "# === Simple U-Net ===\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels=6, out_channels=1):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, out_channels, 3, padding=1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# === Custom Dataset for 6 inputs per sample ===\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, input_dirs, label_dirs, transform=None):\n",
    "        self.input_dirs = input_dirs  # List of 3 input folders\n",
    "        self.label_dirs = label_dirs  # List of 3 corresponding label folders\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_names = sorted(os.listdir(input_dirs[0]))  # Assume all folders aligned\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_tensors = []\n",
    "        for input_dir in self.input_dirs:\n",
    "            img_path = os.path.join(input_dir, self.image_names[idx])\n",
    "            img = Image.open(img_path).convert(\"L\")\n",
    "            img = apply_ahe(img)\n",
    "            input_tensors.append(transforms.ToTensor()(img))\n",
    "\n",
    "        # Concatenate along channel dimension => (6, H, W)\n",
    "        input_tensor = torch.cat(input_tensors, dim=0)\n",
    "\n",
    "        # Use only one label folder for training\n",
    "        label_path = os.path.join(self.label_dirs[0], self.image_names[idx])\n",
    "        label_img = Image.open(label_path).convert(\"L\")\n",
    "        label_tensor = transforms.ToTensor()(label_img)\n",
    "\n",
    "        return input_tensor, label_tensor\n",
    "\n",
    "# === Train and Save Model ===\n",
    "def train_and_save_model():\n",
    "    input_dirs = [\n",
    "        r\"E:\\EmbryoAnalysis\\EmbryoAnalysis\\Dataset\\embryo_dataset_F15\\embryo_dataset_F15\",\n",
    "        r\"E:\\EmbryoAnalysis\\EmbryoAnalysis\\Dataset\\embryo_dataset_F30\\embryo_dataset_F30\",\n",
    "        r\"E:\\EmbryoAnalysis\\EmbryoAnalysis\\Dataset\\embryo_dataset_F45\\embryo_dataset_F45\"\n",
    "    ]\n",
    "    label_dirs = [\n",
    "        r\"E:\\EmbryoAnalysis\\EmbryoAnalysis\\Dataset\\embryo_dataset_F-15\\embryo_dataset_F-15\",\n",
    "        r\"E:\\EmbryoAnalysis\\EmbryoAnalysis\\Dataset\\embryo_dataset_F-30\\embryo_dataset_F-30\",\n",
    "        r\"E:\\EmbryoAnalysis\\EmbryoAnalysis\\Dataset\\embryo_dataset_F-45\\embryo_dataset_F-45\"\n",
    "    ]\n",
    "\n",
    "    dataset = MyDataset(input_dirs, label_dirs)\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SimpleUNet().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"[Epoch {epoch+1}/5] Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "    print(\"[✓] Model saved as trained_model.pth\")\n",
    "\n",
    "# === Test the Saved Model ===\n",
    "def test_model():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SimpleUNet().to(device)\n",
    "    model.load_state_dict(torch.load(\"trained_model.pth\", map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    input_dirs = [\n",
    "        \"test/F15\", \"test/F30\", \"test/F45\"\n",
    "    ]\n",
    "    test_names = sorted(os.listdir(input_dirs[0]))\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "    for name in test_names:\n",
    "        inputs = []\n",
    "        for folder in input_dirs:\n",
    "            img_path = os.path.join(folder, name)\n",
    "            img = Image.open(img_path).convert(\"L\")\n",
    "            img = apply_ahe(img)\n",
    "            inputs.append(transforms.ToTensor()(img))\n",
    "        input_tensor = torch.cat(inputs, dim=0).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "\n",
    "        out_img = output.squeeze().cpu().numpy() * 255\n",
    "        out_img = Image.fromarray(out_img.astype(np.uint8))\n",
    "        out_img.save(f\"output/out_{name}\")\n",
    "        print(f\"[✓] Saved: output/out_{name}\")\n",
    "\n",
    "# === Run ===\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_save_model()\n",
    "    test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc28716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
